{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPE 255-03, Fall 2024\n",
    "## Steam CS2 and TF2 Project\n",
    "\n",
    "**Due Date:** 6:00pm on Oct 30th, 2024\n",
    "\n",
    "EDA Project for Steam Items in CS2 and TF2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download fashion_mnist1.csv.\n",
    "The dataset has 10K rows and 785 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>gameid</th>\n",
       "      <th>steamid</th>\n",
       "      <th>num_games_owned</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>playtime_forever</th>\n",
       "      <th>playtime_last_two_weeks</th>\n",
       "      <th>playtime_at_review</th>\n",
       "      <th>last_played</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>steam_purchase</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>hidden_in_steam_china</th>\n",
       "      <th>steam_china_location</th>\n",
       "      <th>primarily_steam_deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176534183</td>\n",
       "      <td>440</td>\n",
       "      <td>76561199075358962</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>26921</td>\n",
       "      <td>27</td>\n",
       "      <td>26921.0</td>\n",
       "      <td>1728195517</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176533586</td>\n",
       "      <td>440</td>\n",
       "      <td>76561198127158652</td>\n",
       "      <td>1124</td>\n",
       "      <td>68</td>\n",
       "      <td>9220</td>\n",
       "      <td>0</td>\n",
       "      <td>9220.0</td>\n",
       "      <td>1726398332</td>\n",
       "      <td>czech</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176533564</td>\n",
       "      <td>440</td>\n",
       "      <td>76561199178829199</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1645151002</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176533493</td>\n",
       "      <td>440</td>\n",
       "      <td>76561199783055220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>677</td>\n",
       "      <td>516</td>\n",
       "      <td>677.0</td>\n",
       "      <td>1728261916</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176533284</td>\n",
       "      <td>440</td>\n",
       "      <td>76561198157582622</td>\n",
       "      <td>165</td>\n",
       "      <td>9</td>\n",
       "      <td>162721</td>\n",
       "      <td>4986</td>\n",
       "      <td>162721.0</td>\n",
       "      <td>1728259830</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommendationid  gameid            steamid  num_games_owned  num_reviews  \\\n",
       "0         176534183     440  76561199075358962                0            6   \n",
       "1         176533586     440  76561198127158652             1124           68   \n",
       "2         176533564     440  76561199178829199                8            2   \n",
       "3         176533493     440  76561199783055220                0            1   \n",
       "4         176533284     440  76561198157582622              165            9   \n",
       "\n",
       "   playtime_forever  playtime_last_two_weeks  playtime_at_review  last_played  \\\n",
       "0             26921                       27             26921.0   1728195517   \n",
       "1              9220                        0              9220.0   1726398332   \n",
       "2                36                        0                36.0   1645151002   \n",
       "3               677                      516               677.0   1728261916   \n",
       "4            162721                     4986            162721.0   1728259830   \n",
       "\n",
       "     language  ...  votes_up  votes_funny  weighted_vote_score  comment_count  \\\n",
       "0     english  ...         0            0              0.00000              0   \n",
       "1       czech  ...         1            0              0.52381              0   \n",
       "2  portuguese  ...         0            0              0.00000              0   \n",
       "3     english  ...         0            0              0.00000              0   \n",
       "4     english  ...         0            0              0.00000              0   \n",
       "\n",
       "   steam_purchase  received_for_free  written_during_early_access  \\\n",
       "0           False              False                        False   \n",
       "1           False              False                        False   \n",
       "2           False              False                        False   \n",
       "3           False              False                        False   \n",
       "4           False              False                        False   \n",
       "\n",
       "   hidden_in_steam_china  steam_china_location  primarily_steam_deck  \n",
       "0                   True                   NaN                 False  \n",
       "1                   True                   NaN                 False  \n",
       "2                   True                   NaN                 False  \n",
       "3                   True                   NaN                 False  \n",
       "4                   True                   NaN                 False  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('reviews_440.csv')\n",
    "data.head()\n",
    "\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Remove Duplicates from CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./CS2Reviews\\\\CombinedCS2Reviews.csv', './CS2Reviews\\\\reviews_730_01.csv', './CS2Reviews\\\\reviews_730_02.csv', './CS2Reviews\\\\reviews_730_03.csv', './CS2Reviews\\\\reviews_730_04.csv', './CS2Reviews\\\\reviews_730_05.csv', './CS2Reviews\\\\reviews_730_06.csv', './CS2Reviews\\\\reviews_730_07.csv', './CS2Reviews\\\\reviews_730_08.csv', './CS2Reviews\\\\reviews_730_09.csv', './CS2Reviews\\\\reviews_730_10.csv', './CS2Reviews\\\\reviews_730_11.csv', './CS2Reviews\\\\reviews_730_12.csv', './CS2Reviews\\\\reviews_730_13.csv', './CS2Reviews\\\\reviews_730_14.csv', './CS2Reviews\\\\reviews_730_15.csv', './CS2Reviews\\\\reviews_730_16.csv', './CS2Reviews\\\\reviews_730_17.csv', './CS2Reviews\\\\reviews_730_18.csv', './CS2Reviews\\\\reviews_730_19.csv', './CS2Reviews\\\\reviews_730_20.csv', './CS2Reviews\\\\reviews_730_21.csv', './CS2Reviews\\\\reviews_730_22.csv', './CS2Reviews\\\\reviews_730_23.csv', './CS2Reviews\\\\reviews_730_combined.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:10: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_df = pd.read_csv(file_paths[0])\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n",
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\1463797543.py:15: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  next_df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([combined_df, next_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Save the final deduplicated result\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m combined_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./CS2Reviews/CombinedCS2Reviews.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_body()\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_chunk(start_i, end_i)\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:309\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    306\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[0;32m    307\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[1;32m--> 309\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mto_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m    310\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[0;32m    312\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:512\u001b[0m, in \u001b[0;36mBaseBlockManager.to_native_types\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_native_types\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    508\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_native_types\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:531\u001b[0m, in \u001b[0;36mBlock.to_native_types\u001b[1;34m(self, na_rep, quoting, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_native_types\u001b[39m(\u001b[38;5;28mself\u001b[39m, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[0;32m    530\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[1;32m--> 531\u001b[0m     result \u001b[38;5;241m=\u001b[39m to_native_types(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, na_rep\u001b[38;5;241m=\u001b[39mna_rep, quoting\u001b[38;5;241m=\u001b[39mquoting, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(result)\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:2568\u001b[0m, in \u001b[0;36mto_native_types\u001b[1;34m(values, na_rep, quoting, float_format, decimal, **kwargs)\u001b[0m\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n\u001b[0;32m   2567\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2568\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m   2569\u001b[0m     itemsize \u001b[38;5;241m=\u001b[39m writers\u001b[38;5;241m.\u001b[39mword_len(na_rep)\n\u001b[0;32m   2571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m _dtype_obj \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quoting \u001b[38;5;129;01mand\u001b[39;00m itemsize:\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:183\u001b[0m, in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m NDFrame:\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _isna(obj)\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:212\u001b[0m, in \u001b[0;36m_isna\u001b[1;34m(obj, inf_as_na)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _isna_array(obj, inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_can_hold_na:\n",
      "File \u001b[1;32mc:\\Users\\chaoa\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:302\u001b[0m, in \u001b[0;36m_isna_array\u001b[1;34m(values, inf_as_na)\u001b[0m\n\u001b[0;32m    300\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misfinite(values)\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(values)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List of file paths\n",
    "# C:\\Users\\chaoa\\Downloads\\CMPE255\\CS2Reviews\\reviews_730_01.csv\n",
    "file_paths = sorted(glob.glob('./CS2Reviews/*.csv'))  # Sort if order matters\n",
    "\n",
    "print(file_paths)\n",
    "\n",
    "# Start by loading the first file as the initial base\n",
    "combined_df = pd.read_csv(file_paths[0])\n",
    "\n",
    "# Iterate over remaining files and combine without duplicates\n",
    "for file_path in file_paths[1:]:\n",
    "    # Load the next file\n",
    "    next_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Remove entries in `next_df` that already exist in `combined_df`\n",
    "    next_df = next_df[~next_df['recommendationid'].isin(combined_df['recommendationid'])]\n",
    "    \n",
    "    # Concatenate the unique entries to `combined_df`\n",
    "    combined_df = pd.concat([combined_df, next_df], ignore_index=True)\n",
    "\n",
    "# Save the final deduplicated result\n",
    "combined_df.to_csv(\"./CS2Reviews/CombinedCS2Reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\776911025.py:2: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./CS2Reviews/CombinedCS2Reviews.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8335510 entries, 0 to 8335509\n",
      "Data columns (total 24 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   recommendationid             int64  \n",
      " 1   gameid                       int64  \n",
      " 2   steamid                      int64  \n",
      " 3   num_games_owned              int64  \n",
      " 4   num_reviews                  int64  \n",
      " 5   playtime_forever             float64\n",
      " 6   playtime_last_two_weeks      float64\n",
      " 7   playtime_at_review           float64\n",
      " 8   last_played                  float64\n",
      " 9   language                     object \n",
      " 10  review_length                int64  \n",
      " 11  timestamp_created            int64  \n",
      " 12  timestamp_updated            int64  \n",
      " 13  voted_up                     bool   \n",
      " 14  votes_up                     int64  \n",
      " 15  votes_funny                  int64  \n",
      " 16  weighted_vote_score          float64\n",
      " 17  comment_count                int64  \n",
      " 18  steam_purchase               bool   \n",
      " 19  received_for_free            bool   \n",
      " 20  written_during_early_access  bool   \n",
      " 21  hidden_in_steam_china        bool   \n",
      " 22  steam_china_location         object \n",
      " 23  primarily_steam_deck         bool   \n",
      "dtypes: bool(6), float64(5), int64(11), object(2)\n",
      "memory usage: 1.2+ GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chaoa\\AppData\\Local\\Temp\\ipykernel_31988\\776911025.py:6: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cv = pd.read_csv('./CS2Reviews/reviews_730_combined.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8367210 entries, 0 to 8367209\n",
      "Data columns (total 24 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   recommendationid             int64  \n",
      " 1   gameid                       int64  \n",
      " 2   steamid                      int64  \n",
      " 3   num_games_owned              int64  \n",
      " 4   num_reviews                  int64  \n",
      " 5   playtime_forever             float64\n",
      " 6   playtime_last_two_weeks      float64\n",
      " 7   playtime_at_review           float64\n",
      " 8   last_played                  float64\n",
      " 9   language                     object \n",
      " 10  review_length                int64  \n",
      " 11  timestamp_created            int64  \n",
      " 12  timestamp_updated            int64  \n",
      " 13  voted_up                     bool   \n",
      " 14  votes_up                     int64  \n",
      " 15  votes_funny                  int64  \n",
      " 16  weighted_vote_score          float64\n",
      " 17  comment_count                int64  \n",
      " 18  steam_purchase               bool   \n",
      " 19  received_for_free            bool   \n",
      " 20  written_during_early_access  bool   \n",
      " 21  hidden_in_steam_china        bool   \n",
      " 22  steam_china_location         object \n",
      " 23  primarily_steam_deck         bool   \n",
      "dtypes: bool(6), float64(5), int64(11), object(2)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset\n",
    "df = pd.read_csv('./CS2Reviews/CombinedCS2Reviews.csv')\n",
    "\n",
    "df.info()\n",
    "\n",
    "cv = pd.read_csv('./CS2Reviews/reviews_730_combined.csv')\n",
    "\n",
    "cv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Duplicate Blobs at the beginning or end of files (situations where requests halted prematurely and overlap occurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./CS2Prices/*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Sort if order matters\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_paths)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Start by loading the first file as the initial base\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "file_paths = sorted(glob.glob('./CS2Prices/*.csv'))  # Sort if order matters\n",
    "\n",
    "print(file_paths)\n",
    "\n",
    "# Start by loading the first file as the initial base\n",
    "combined_df = pd.read_csv(file_paths[0])\n",
    "\n",
    "# Iterate over remaining files and combine without duplicates\n",
    "for file_path in file_paths[1:]:\n",
    "    # Load the next file\n",
    "    next_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Remove entries in `next_df` that already exist in `combined_df`\n",
    "    next_df = next_df[~next_df.set_index(['Item Name', 'Date']).index.isin(combined_df.set_index(['Item Name', 'Date']).index)]\n",
    "    \n",
    "    # Concatenate the unique entries to `combined_df`\n",
    "    combined_df = pd.concat([combined_df, next_df], ignore_index=True)\n",
    "\n",
    "# Save the final deduplicated result\n",
    "combined_df.to_csv(\"./CS2Prices/CombinedCS2Prices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15524405 entries, 0 to 15524404\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Item Name  object \n",
      " 1   Parent     object \n",
      " 2   Date       object \n",
      " 3   Price      float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 592.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./CS2Prices/CombinedCS2Prices.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF2 Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"./TF2Prices/steam_440_price_history_1_31.csv\", \"./TF2Prices/steam_price_history_tf2_32-103.csv\"]\n",
    "\n",
    "# Start by loading the first file as the initial base\n",
    "combined_df = pd.read_csv(file_paths[0])\n",
    "\n",
    "# Iterate over remaining files and combine without duplicates\n",
    "for file_path in file_paths[1:]:\n",
    "    # Load the next file\n",
    "    next_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Remove entries in `next_df` that already exist in `combined_df`\n",
    "    next_df = next_df[~next_df.set_index(['Item Name', 'Parent', 'Date']).index.isin(combined_df.set_index(['Item Name', 'Parent', 'Date']).index)]\n",
    "    \n",
    "    # Concatenate the unique entries to `combined_df`\n",
    "    combined_df = pd.concat([combined_df, next_df], ignore_index=True)\n",
    "\n",
    "# Save the final deduplicated result\n",
    "combined_df.to_csv(\"./TF2Prices/CombinedTF2Prices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with multiple parents:\n",
      "                        Item Name                Date  \\\n",
      "0        A Color Similar to Slate  Apr 01 2013 01: +0   \n",
      "1        A Color Similar to Slate  Apr 01 2014 01: +0   \n",
      "2        A Color Similar to Slate  Apr 01 2015 01: +0   \n",
      "3        A Color Similar to Slate  Apr 01 2016 01: +0   \n",
      "4        A Color Similar to Slate  Apr 01 2017 01: +0   \n",
      "...                           ...                 ...   \n",
      "1071332         Zepheniah's Greed  Sep 30 2024 18: +0   \n",
      "1071333         Zepheniah's Greed  Sep 30 2024 19: +0   \n",
      "1071334         Zepheniah's Greed  Sep 30 2024 20: +0   \n",
      "1071335         Zepheniah's Greed  Sep 30 2024 21: +0   \n",
      "1071336         Zepheniah's Greed  Sep 30 2024 23: +0   \n",
      "\n",
      "                                                    Parent  Price  Volume  \n",
      "0        [Mann Co. Supply Crate Series #9, Mann Co. Sup...  0.931      18  \n",
      "1        [Mann Co. Supply Crate Series #9, Mann Co. Sup...  0.854      12  \n",
      "2        [Mann Co. Supply Crate Series #9, Mann Co. Sup...  0.835      19  \n",
      "3        [Mann Co. Supply Crate Series #9, Mann Co. Sup...  1.250       5  \n",
      "4        [Mann Co. Supply Crate Series #9, Mann Co. Sup...  1.009       6  \n",
      "...                                                    ...    ...     ...  \n",
      "1071332  [Mann Co. Supply Crate Series #10, Mann Co. Su...  0.270       5  \n",
      "1071333  [Mann Co. Supply Crate Series #10, Mann Co. Su...  0.264       1  \n",
      "1071334  [Mann Co. Supply Crate Series #10, Mann Co. Su...  0.274       2  \n",
      "1071335  [Mann Co. Supply Crate Series #10, Mann Co. Su...  0.270       1  \n",
      "1071336  [Mann Co. Supply Crate Series #10, Mann Co. Su...  0.270       1  \n",
      "\n",
      "[339671 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Accounting for items with multiple parents\n",
    "\n",
    "combined_df = pd.read_csv(\"./TF2Prices/CombinedTF2Prices.csv\")\n",
    "\n",
    "# # Identify rows with duplicates\n",
    "# duplicate_groups = combined_df.groupby(['Item Name', 'Date']).filter(lambda x: len(x) > 1)\n",
    "\n",
    "# print(\"Combined rows (only those with duplicates):\")\n",
    "# print(duplicate_groups)\n",
    "\n",
    "# Group by 'Item Name' and 'Date' and aggregate with Parent as a list\n",
    "combined_df = combined_df.groupby(['Item Name', 'Date'], as_index=False).agg({\n",
    "    'Parent': lambda x: list(x.unique()),\n",
    "    'Price': 'first',\n",
    "    'Volume': 'first'\n",
    "})\n",
    "\n",
    "# Filter rows where the 'Parent' list has more than one entry\n",
    "multiple_parents = combined_df[combined_df['Parent'].apply(len) > 1]\n",
    "\n",
    "print(\"Rows with multiple parents:\")\n",
    "print(multiple_parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Combined Datasets\n",
    "combined_df.to_json('./TF2Prices/CombinedTF2Prices_MultiParents.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = pd.read_csv('./CS2Prices/CombinedCS2Prices.csv')\n",
    "\n",
    "tf = pd.read_json('./TF2Prices/CombinedTF2Prices_MultiParents.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 DateTime --> Day / Month / Year Columns (Chronological Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-27 09:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def convert_date_time(date_string):\n",
    "    # Parse the date and time, ignoring the timezone offset\n",
    "    dt = datetime.strptime(date_string[:-3], \"%b %d %Y %H:\")\n",
    "\n",
    "    # Add the timezone offset\n",
    "    offset = int(date_string[-2:])\n",
    "    dt = dt + timedelta(hours=offset)\n",
    "\n",
    "    return dt\n",
    "\n",
    "date_string = \"Oct 27 2024 09: +0\"\n",
    "converted_dt = convert_date_time(date_string)\n",
    "print(converted_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date  Day  Month  Year            Iso_Date\n",
      "0         Aug 14 2013 01: +0   14      8  2013 2013-08-14 01:00:00\n",
      "1         Aug 15 2013 01: +0   15      8  2013 2013-08-15 01:00:00\n",
      "2         Aug 16 2013 01: +0   16      8  2013 2013-08-16 01:00:00\n",
      "3         Aug 17 2013 01: +0   17      8  2013 2013-08-17 01:00:00\n",
      "4         Aug 18 2013 01: +0   18      8  2013 2013-08-18 01:00:00\n",
      "...                      ...  ...    ...   ...                 ...\n",
      "15524400  Oct 25 2024 13: +0   25     10  2024 2024-10-25 13:00:00\n",
      "15524401  Oct 25 2024 17: +0   25     10  2024 2024-10-25 17:00:00\n",
      "15524402  Oct 26 2024 01: +0   26     10  2024 2024-10-26 01:00:00\n",
      "15524403  Oct 26 2024 05: +0   26     10  2024 2024-10-26 05:00:00\n",
      "15524404  Oct 26 2024 11: +0   26     10  2024 2024-10-26 11:00:00\n",
      "\n",
      "[15524405 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "cs['Iso_Date'] = cs['Date'].apply(convert_date_time) # ISO 8601 format (YYYY-MM-DD)\n",
    "\n",
    "cs['Day'] = cs['Iso_Date'].dt.day\n",
    "cs['Month'] = cs['Iso_Date'].dt.month # integer month\n",
    "cs['Year'] = cs['Iso_Date'].dt.year\n",
    "\n",
    "print(cs[['Date', 'Day', 'Month', 'Year', 'Iso_Date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.to_csv(\"./CS2Prices/CombinedCS2Prices_Dates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date  Day  Month  Year            Iso_Date\n",
      "0        Apr 01 2013 01: +0    1      4  2013 2013-04-01 01:00:00\n",
      "1        Apr 01 2014 01: +0    1      4  2014 2014-04-01 01:00:00\n",
      "2        Apr 01 2015 01: +0    1      4  2015 2015-04-01 01:00:00\n",
      "3        Apr 01 2016 01: +0    1      4  2016 2016-04-01 01:00:00\n",
      "4        Apr 01 2017 01: +0    1      4  2017 2017-04-01 01:00:00\n",
      "...                     ...  ...    ...   ...                 ...\n",
      "1071332  Sep 30 2024 18: +0   30      9  2024 2024-09-30 18:00:00\n",
      "1071333  Sep 30 2024 19: +0   30      9  2024 2024-09-30 19:00:00\n",
      "1071334  Sep 30 2024 20: +0   30      9  2024 2024-09-30 20:00:00\n",
      "1071335  Sep 30 2024 21: +0   30      9  2024 2024-09-30 21:00:00\n",
      "1071336  Sep 30 2024 23: +0   30      9  2024 2024-09-30 23:00:00\n",
      "\n",
      "[1071337 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "tf['Iso_Date'] = tf['Date'].apply(convert_date_time) # ISO 8601 format (YYYY-MM-DD)\n",
    "\n",
    "tf['Day'] = tf['Iso_Date'].dt.day\n",
    "tf['Month'] = tf['Iso_Date'].dt.month # integer month\n",
    "tf['Year'] = tf['Iso_Date'].dt.year\n",
    "\n",
    "print(tf[['Date', 'Day', 'Month', 'Year', 'Iso_Date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf['Iso_Date'] = tf['Iso_Date'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "tf.to_json('./TF2Prices/CombinedTF2Prices_MultiParents_Dates.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Lifespan = Current date - first date (Chronological Data)\n",
    "\n",
    "CS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15524405 entries, 0 to 15524404\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Item Name  object \n",
      " 1   Parent     object \n",
      " 2   Date       object \n",
      " 3   Price      float64\n",
      " 4   Volume     int64  \n",
      " 5   Iso_Date   object \n",
      " 6   Day        int64  \n",
      " 7   Month      int64  \n",
      " 8   Year       int64  \n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 1.0+ GB\n",
      "                                          Item Name        Parent  \\\n",
      "0                                 CS:GO Weapon Case           NaN   \n",
      "1                                 CS:GO Weapon Case           NaN   \n",
      "2                                 CS:GO Weapon Case           NaN   \n",
      "3                                 CS:GO Weapon Case           NaN   \n",
      "4                                 CS:GO Weapon Case           NaN   \n",
      "...                                             ...           ...   \n",
      "15524400  StatTrak M4A1-S | Vaporwave (Factory New)  Gallery Case   \n",
      "15524401  StatTrak M4A1-S | Vaporwave (Factory New)  Gallery Case   \n",
      "15524402  StatTrak M4A1-S | Vaporwave (Factory New)  Gallery Case   \n",
      "15524403  StatTrak M4A1-S | Vaporwave (Factory New)  Gallery Case   \n",
      "15524404  StatTrak M4A1-S | Vaporwave (Factory New)  Gallery Case   \n",
      "\n",
      "                        Date    Price  Volume            Iso_Date  Day  Month  \\\n",
      "0         Aug 14 2013 01: +0    8.528      38 2013-08-14 01:00:00   14      8   \n",
      "1         Aug 15 2013 01: +0    5.436    5412 2013-08-15 01:00:00   15      8   \n",
      "2         Aug 16 2013 01: +0    3.351    9877 2013-08-16 01:00:00   16      8   \n",
      "3         Aug 17 2013 01: +0    2.621   11050 2013-08-17 01:00:00   17      8   \n",
      "4         Aug 18 2013 01: +0    2.665   11485 2013-08-18 01:00:00   18      8   \n",
      "...                      ...      ...     ...                 ...  ...    ...   \n",
      "15524400  Oct 25 2024 13: +0  473.558       1 2024-10-25 13:00:00   25     10   \n",
      "15524401  Oct 25 2024 17: +0  515.004       1 2024-10-25 17:00:00   25     10   \n",
      "15524402  Oct 26 2024 01: +0  450.975       1 2024-10-26 01:00:00   26     10   \n",
      "15524403  Oct 26 2024 05: +0  537.700       1 2024-10-26 05:00:00   26     10   \n",
      "15524404  Oct 26 2024 11: +0  519.566       1 2024-10-26 11:00:00   26     10   \n",
      "\n",
      "          Year         Lifespan  Lifespan_Days  \n",
      "0         2013  0 days 00:00:00              0  \n",
      "1         2013  1 days 00:00:00              1  \n",
      "2         2013  2 days 00:00:00              2  \n",
      "3         2013  3 days 00:00:00              3  \n",
      "4         2013  4 days 00:00:00              4  \n",
      "...        ...              ...            ...  \n",
      "15524400  2024 14 days 14:00:00             14  \n",
      "15524401  2024 14 days 18:00:00             14  \n",
      "15524402  2024 15 days 02:00:00             15  \n",
      "15524403  2024 15 days 06:00:00             15  \n",
      "15524404  2024 15 days 12:00:00             15  \n",
      "\n",
      "[15524405 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "cs = pd.read_csv('./CS2Prices/CombinedCS2Prices_Dates.csv')\n",
    "\n",
    "# cs.info()\n",
    "# Convert 'Iso_Date' to datetime\n",
    "cs['Iso_Date'] = pd.to_datetime(cs['Iso_Date'])\n",
    "\n",
    "# Find the first occurrence of each item\n",
    "first_occurrence = cs.groupby('Item Name')['Iso_Date'].transform('min')\n",
    "\n",
    "# Calculate Lifespan by subtracting the first occurrence date from the current row's date\n",
    "cs['Lifespan'] = cs['Iso_Date'] - first_occurrence\n",
    "\n",
    "# Optional: Convert Lifespan to total days\n",
    "cs['Lifespan_Days'] = cs['Lifespan'].dt.days\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.to_csv(\"./CS2Prices/CombinedCS2Prices_Dates_Lifetime.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Item Name                Date  \\\n",
      "0  A Color Similar to Slate  Apr 01 2013 01: +0   \n",
      "1  A Color Similar to Slate  Apr 01 2014 01: +0   \n",
      "2  A Color Similar to Slate  Apr 01 2015 01: +0   \n",
      "3  A Color Similar to Slate  Apr 01 2016 01: +0   \n",
      "4  A Color Similar to Slate  Apr 01 2017 01: +0   \n",
      "\n",
      "                                              Parent  Price  Volume  \\\n",
      "0  [Mann Co. Supply Crate Series #9, Mann Co. Sup...  0.931      18   \n",
      "1  [Mann Co. Supply Crate Series #9, Mann Co. Sup...  0.854      12   \n",
      "2  [Mann Co. Supply Crate Series #9, Mann Co. Sup...  0.835      19   \n",
      "3  [Mann Co. Supply Crate Series #9, Mann Co. Sup...  1.250       5   \n",
      "4  [Mann Co. Supply Crate Series #9, Mann Co. Sup...  1.009       6   \n",
      "\n",
      "        Iso_Date  Day  Month  Year  \n",
      "0  1364778000000    1      4  2013  \n",
      "1  1396314000000    1      4  2014  \n",
      "2  1427850000000    1      4  2015  \n",
      "3  1459472400000    1      4  2016  \n",
      "4  1491008400000    1      4  2017  \n"
     ]
    }
   ],
   "source": [
    "tf = pd.read_json('./TF2Prices/CombinedTF2Prices_MultiParents_Dates.json', orient='records', lines=True)\n",
    "\n",
    "print(tf[:5])\n",
    "\n",
    "# tf['Iso_Date'] = pd.to_datetime(tf['Iso_Date'])\n",
    "\n",
    "# print(tf['Iso_Date'][:5])\n",
    "\n",
    "# # Find the first occurrence of each item\n",
    "# first_occurrence = tf.groupby('Item Name')['Iso_Date'].transform('min')\n",
    "\n",
    "# # Calculate Lifespan by subtracting the first occurrence date from the current row's date\n",
    "# tf['Lifespan'] = tf['Iso_Date'] - first_occurrence\n",
    "\n",
    "# # print(tf['Lifespan'])\n",
    "\n",
    "# # Optional: Convert Lifespan to total days\n",
    "# tf['Lifespan_Days'] = tf['Lifespan'].dt.days\n",
    "\n",
    "# print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.to_json('./TF2Prices/CombinedTF2Prices_MultiParents_Dates_Lifetime.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Concurrent Players (Social Data)\n",
    "\n",
    "CS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_players = pd.read_csv('./PlayerCount/cs2playercount.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_players = pd.read_csv('./PlayerCount/tf2playercount.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Game Price (Financial Data)\n",
    "\n",
    "CS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_price = pd.read_csv('./GamePrice/cs2gamepricehistory.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF2\n",
    "\n",
    "Use Orange Box (TF2 included in bundle)\n",
    "F2P June 23, 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_price = pd.read_csv('./GamePrice/orangeboxgamepricehistory.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Review Sentiment\n",
    "\n",
    "CS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Outlier Detection and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Pearson Coefficients and Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
